{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with CART Trees - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we shall put into practice, the skills shown in the previous code along. We shall use a simple dataset from Kaggle, called the [\"Petrol Consumption Dataset\"](https://www.kaggle.com/harinir/petrol-consumption) which entails the petrol consumption for a bunch of examples, based on drivers' features.\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "- Conduct a regression experiment using CART trees\n",
    "- Evaluate the model fit and study the impact of hyper parameters on the final tree\n",
    "- Understand training, prediction, evaluation and visualizations required to run regression experiments using trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset `petrol_consumption.csv` and view its head and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
      "0         9.0            3571            1976                         0.525   \n",
      "1         9.0            4092            1250                         0.572   \n",
      "2         9.0            3865            1586                         0.580   \n",
      "3         7.5            4870            2351                         0.529   \n",
      "4         8.0            4399             431                         0.544   \n",
      "\n",
      "   Petrol_Consumption  \n",
      "0                 541  \n",
      "1                 524  \n",
      "2                 561  \n",
      "3                 414  \n",
      "4                 410  \n",
      "(48, 5)\n",
      "       Petrol_tax  Average_income  Paved_Highways  \\\n",
      "count   48.000000       48.000000       48.000000   \n",
      "mean     7.668333     4241.833333     5565.416667   \n",
      "std      0.950770      573.623768     3491.507166   \n",
      "min      5.000000     3063.000000      431.000000   \n",
      "25%      7.000000     3739.000000     3110.250000   \n",
      "50%      7.500000     4298.000000     4735.500000   \n",
      "75%      8.125000     4578.750000     7156.000000   \n",
      "max     10.000000     5342.000000    17782.000000   \n",
      "\n",
      "       Population_Driver_licence(%)  Petrol_Consumption  \n",
      "count                     48.000000           48.000000  \n",
      "mean                       0.570333          576.770833  \n",
      "std                        0.055470          111.885816  \n",
      "min                        0.451000          344.000000  \n",
      "25%                        0.529750          509.500000  \n",
      "50%                        0.564500          568.500000  \n",
      "75%                        0.595250          632.750000  \n",
      "max                        0.724000          968.000000  \n"
     ]
    }
   ],
   "source": [
    "# Read the dataset and view head and dimensions\n",
    "df = pd.read_csv('petrol_consumption.csv')\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.describe())\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the basic statistics for the dataset and inspect the target variable `Petrol_Consumption`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataset\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features, labels and train/test datasets with a 80/20 split\n",
    "\n",
    "As with the classification task, we will divide our data into attributes/features and labels and consequently into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Create datasets for training and test\n",
    "X = df.drop(columns=['Petrol_Consumption'])\n",
    "y = df['Petrol_Consumption']\n",
    "\n",
    "# Code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an instance of CART regressor and fit the data to the model \n",
    "\n",
    "As mentioned earlier, for a regression task we'll use a different `sklearn` class than we did for the classification task. The class we'll be using here is the `DecisionTreeRegressor` class, as opposed to the `DecisionTreeClassifier` from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a regression tree model with training data \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "r = DecisionTreeRegressor()\n",
    "r. fit(X_train, y_train)\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Using test set, make predictions and calculate the MAE, MSE and RMSE\n",
    " \n",
    "To evaluate performance of the regression algorithm, the commonly used metrics are mean absolute error, mean squared error, and root mean squared error. The `sklearn` library contains functions that can help calculate these values for us. To do so, use this code from the `metrics` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 56.2\n",
      "Mean Squared Error: 6269.0\n",
      "Root Mean Squared Error: 79.17701686727027\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate the predictions\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "y_pred = r.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "#r2 = (r2_score(y_test, y_pred))\n",
    "# Code here\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {np.sqrt(mse)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the tree using `graphviz`\n",
    "\n",
    "Let's visualize our learnt tree as we have been doing in previous lessons and labs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree using graph viz library \n",
    "\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional \n",
    "\n",
    "- In order to understand and interpret a tree structure, we need some domain knowledge in which the data was generated. That can help us inspect each leaf and investigate/prune the tree based on qualitative analysis. \n",
    "\n",
    "- Look at the hyper parameters used in the regression tree, check their values ranges in official doc and try running some optimization by growing a number of trees in a loop. \n",
    "\n",
    "- Use a dataset that you are familiar with and run tree regression to see if you can interpret the results.\n",
    "\n",
    "- Check for outliers, try normalization and see the impact on the output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this lesson, we developed a tree regressor architecture to train the regressor and predict values for unseen data. We saw that with a vanilla approach, the results were not so great, and this requires further pre-tuning of the model (what we described as hyper parameter optimization OR pruning in the case of trees. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
